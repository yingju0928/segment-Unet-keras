{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Model' has no attribute 'placeholder_inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8cf67bdc32b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-8cf67bdc32b8>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         images, labels = tf.keras.Model.placeholder_inputs(\n\u001b[0m\u001b[0;32m     47\u001b[0m             batch_size=BATCH_SIZE)\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Model' has no attribute 'placeholder_inputs'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# from tensorflow.keras import tf.keras.Model\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "DATA_NAME = 'Data'\n",
    "TRAIN_SOURCE = \"Train\"\n",
    "TEST_SOURCE = 'Test'\n",
    "RUN_NAME = \"SELU_Run03\"\n",
    "OUTPUT_NAME = 'Output'\n",
    "CHECKPOINT_FN = 'model.ckpt'\n",
    "\n",
    "WORKING_DIR = os.getcwd()\n",
    "\n",
    "TRAIN_DATA_DIR = os.path.join(WORKING_DIR, DATA_NAME, TRAIN_SOURCE)\n",
    "TEST_DATA_DIR = os.path.join(WORKING_DIR, DATA_NAME, TEST_SOURCE)\n",
    "\n",
    "ROOT_LOG_DIR = os.path.join(WORKING_DIR, OUTPUT_NAME)\n",
    "LOG_DIR = os.path.join(ROOT_LOG_DIR, RUN_NAME)\n",
    "CHECKPOINT_FL = os.path.join(LOG_DIR, CHECKPOINT_FN)\n",
    "\n",
    "TRAIN_WRITER_DIR = os.path.join(LOG_DIR, TRAIN_SOURCE)\n",
    "TEST_WRITER_DIR = os.path.join(LOG_DIR, TEST_SOURCE)\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "MAX_STEP = 2500\n",
    "BATCH_SIZE = 6\n",
    "\n",
    "LEARNING_RATE = 1e-04\n",
    "\n",
    "SAVE_RESULTS_INTERVAL = 5\n",
    "SAVE_CHECKPOINT_INTERVAL = 100\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_data = TRAIN_DATA_DIR\n",
    "    test_data = TEST_DATA_DIR\n",
    "\n",
    "    g = tf.Graph()\n",
    "\n",
    "    with g.as_default():\n",
    "\n",
    "        images, labels = tf.keras.Model.placeholder_inputs(\n",
    "            batch_size=BATCH_SIZE)\n",
    "\n",
    "        logits, softmax_logits = tf.keras.Model.inference(\n",
    "            images, class_inc_bg=2)\n",
    "\n",
    "        tf.keras.Model.add_output_images(\n",
    "            images=images, logits=logits, labels=labels)\n",
    "\n",
    "        loss = tf.keras.Model.loss_calc(logits=logits, labels=labels)\n",
    "\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "        train_op = tf.keras.Model.training(\n",
    "            loss=loss, learning_rate=1e-04, global_step=global_step)\n",
    "\n",
    "        accuracy = tf.keras.Model.evaluation(logits=logits, labels=labels)\n",
    "\n",
    "        summary = tf.summary.merge_all()\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "    sm = tf.train.SessionManager(graph=g)\n",
    "\n",
    "    with sm.prepare_session(\"\", init_op=init, saver=saver, checkpoint_dir=LOG_DIR) as sess:\n",
    "\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        train_writer = tf.summary.FileWriter(TRAIN_WRITER_DIR, sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(TEST_WRITER_DIR)\n",
    "\n",
    "        global_step_value, = sess.run([global_step])\n",
    "\n",
    "        print(\"Last trained iteration was: \", global_step_value)\n",
    "\n",
    "        try:\n",
    "\n",
    "            while True:\n",
    "\n",
    "                if global_step_value >= MAX_STEP:\n",
    "                    print(\n",
    "                        f\"Reached MAX_STEP: {MAX_STEP} at step: {global_step_value}\")\n",
    "                    break\n",
    "\n",
    "                images_batch, labels_batch = test_data.next_batch(BATCH_SIZE)\n",
    "\n",
    "                feed_dict = {images: images_batch, labels: labels_batch}\n",
    "\n",
    "                if (global_step_value + 1) % SAVE_RESULTS_INTERVAL == 0:\n",
    "                    _, loss_value, accuracy_value, global_step_value, summary_str = sess.run(\n",
    "                        [train_op, loss, accuracy, global_step, summary], feed_dict=feed_dict)\n",
    "                    train_writer.add_summary(\n",
    "                        summary_str, global_step=global_step_value)\n",
    "                    print(\n",
    "                        f\"TRAIN Step: {global_step_value}\\tLoss: {loss_value}\\tAccuracy: {accuracy_value}\")\n",
    "\n",
    "                    images_batch, labels_batch = train_data.next_batch(\n",
    "                        BATCH_SIZE)\n",
    "                    feed_dict = {images: images_batch, labels: labels_batch}\n",
    "\n",
    "                    loss_value, accuracy_value, global_step_value, summary_str = sess.run(\n",
    "                        [loss, accuracy, global_step, summary], feed_dict=feed_dict)\n",
    "                    test_writer.add_summary(\n",
    "                        summary_str, global_step=global_step_value)\n",
    "                    print(\n",
    "                        f\"TEST  Step: {global_step_value}\\tLoss: {loss_value}\\tAccuracy: {accuracy_value}\")\n",
    "\n",
    "                else:\n",
    "                    _, loss_value, accuracy_value, global_step_value = sess.run(\n",
    "                        [train_op, loss, accuracy, global_step], feed_dict=feed_dict)\n",
    "                    print(\n",
    "                        f\"TRAIN Step: {global_step_value}\\tLoss: {loss_value}\\tAccuracy: {accuracy_value}\")\n",
    "\n",
    "                if global_step_value % SAVE_CHECKPOINT_INTERVAL == 0:\n",
    "                    saver.save(sess, CHECKPOINT_FL,\n",
    "                               global_step=global_step_value)\n",
    "                    print(\"Checkpoint Saved\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Exception')\n",
    "            print(e)\n",
    "\n",
    "        train_writer.flush()\n",
    "        test_writer.flush()\n",
    "        saver.save(sess, CHECKPOINT_FL, global_step=global_step_value)\n",
    "        print(\"Checkpoint Saved\")\n",
    "\n",
    "        print(\"Stopping\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
